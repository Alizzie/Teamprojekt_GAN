\chapter{Lösungsbeschreibung}
\section{Training- und Testdaten}
Das Training und die Evaluierung von Generative Adversarial Networks (GANs) erfordern die klare Definition von Trainings- und Testdatensätzen. Der entscheidende Unterschied zwischen diesen Datensätzen besteht darin, dass das Modell während des Trainings auf den Trainingsdaten optimiert wird, während die Testdaten verwendet werden, um die Leistung und die Generalisierungsfähigkeiten des Modells zu bewerten.

\subsection{Datenladung für GAN-Training}
Für das effektive Training von GANs ist der Zugriff auf qualitativ hochwertige Datensätze von entscheidender Bedeutung. In diesem Kontext bietet TensorFlow eine umfassende Sammlung öffentlich verfügbarer Datensätze. Die verwendeten Datensätze werden von der Quelle \url{https://efrosgans.eecs.berkeley.edu} heruntergeladen und lokal extrahiert.

\lstinputlisting[language=pyhaff, caption=Laden eines Datensatzes von einer URL]{code/LadenDatensatz.txt}

Die Transformation und Vorverarbeitung der Bilddaten erfolgt durch die TensorFlow-Datensatz-API. Diese API bietet eine effiziente Datenpipeline für das Laden und Verarbeiten von Daten, insbesondere für den Einsatz in Machine-Learning-Modellen. In den folgenden Implementierungen werden die Datensätze durch eine Liste von Dateipfaden als Zeichenketten erzeugt.

\begin{lstlisting}[language=pyhaff, caption={Erzeugung eines Tensorflow-Dataset aus der CycleGAN Implementierung}, label={cod:createDataset}]
train_horses =  tf.data.Dataset.list_files(str(PATH / 'trainA/*.jpg')) 
\end{lstlisting}

\subsection{Vorverarbeitung des Datensatzes}

Um die Leistung von GAN-Modellen zu optimieren, werden vor dem Training Variationen in den Trainingsdaten eingeführt. Dieser Prozess umfasst Datenjittering und Normalisierung. Durch die Integration von Variationen wird das Modell robuster, da es eine erhöhte Invarianz gegenüber unterschiedlichen Eingabedaten entwickelt. Dies trägt wesentlich dazu bei, eine verbesserte Konvergenz während des Trainings zu erreichen.
\\\newline
Bei Pix2Pix bestehen die Trainingsdaten aus einem Paar von Eingabe- und Zielbildern, während bei CycleGAN unpaare Daten berücksichtigt werden. Um eine konsistente Skalierung mit der Tanh-Aktivierungsfunktion sicherzustellen, werden diese Bilder im Bereich von -1 bis +1 skaliert. Diese Normalisierung ist von entscheidender Bedeutung für die Stabilisierung des Trainingsprozesses. Durch die Bereitstellung eines standardisierten Datensatzes kann das Modell effektiver mit einer verbesserten Lernrate und Konvergenzgeschwindigkeit arbeiten \cite{Radford.2015}.

\begin{lstlisting}[language=pyhaff, caption={Vorverarbeitung des Datensatzes: Normalisierung}, label={cod:normalizing}]
def normalize(image):
    image = (image / 127.5) - 1
    return image
\end{lstlisting}

Datenjittering bezieht sich auf die Einführung von zufälligen Variationen oder Veränderungen in den Trainingsdaten, was in der Implementierung durch zufälliges Zuschneiden und eine zufällige Spiegelung erreicht wird. Die heruntergeladenen Bilder mit einer Auflösung von 256x256 werden zuerst auf eine größere Größe von 286x286 skaliert, wobei die Nearest-Neighbor-Methode verwendet wird. 

\begin{lstlisting}[language=pyhaff, caption={Vorverarbeitung des Datensatzes: Jittering}, label={cod:jittering}]
def random_jitter(image):
    image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    image = tf.image.random_crop(image, size=(286, 286, 3))
    image = tf.image.random_flip_left_right(image)
    return image
\end{lstlisting}

Diese Methode skaliert Bilder einfach und effizient, indem sie für jedes Pixel im skalierten Bild den Farbwert des nächstgelegenen Pixels im Originalbild übernimmt\footnote{\url{https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation} \label{note:nearestNeighbor}}.
Nach dem Skalieren wird das Bild zufällig auf die Originalgröße reduziert und gleichzeitig mit einer Wahrscheinlichkeit von 50\% gespiegelt.
Anschließend werden die Bildpfade mittels der $load\_image$-Funktion geladen und in das resultierende JPEG-Format decodiert (Code \ref{cod:imageLoading}).
\\\newline
Die vorverarbeiteten Trainings- und Testbilder werden darauf in TensorFlow-Datasets integriert. Nachfolgend wird der Trainingsdatensatz zufällig gemischt und in Batches gruppiert, wodurch sichergestellt wird, dass das Modell nicht von der Reihenfolge der Datenpunkte beeinflusst wird.
\lstinputlisting[language=pyhaff, caption=Integration der vorverarbeiteten Trainingsbilder in Tensorflow-Datasets (CycleGAN Implementierung)]{code/LadenBild.txt}

Diese umfassende Vorverarbeitung stellt sicher, dass das GAN-Modell auf optimal vorbereiteten Daten trainiert wird, um eine maximale Leistung und Generalisierungsfähigkeit zu erreichen.

\input{chapters/pix2pix_implementierung.tex}
\input{chapters/cycleGan_implementation.tex}


\section{Training und Hyperparameter}

Im Rahmen des Trainingsprozesses wird eine iterative Methode angewendet, bei der der Generator und der Diskriminator abwechselnd trainiert werden. Dieser Trainingszyklus erstreckt sich über mehrere Epochen. In jeder Epoche werden Bilder durch einen Feed-Forward-Prozess vom Generator generiert und anschließend vom Diskriminator bewertet. Gleichzeitig wird der Diskriminator mit den echten Zielbildern trainiert, um seine Fähigkeit zu verbessern, zwischen echten und generierten Bildern zu unterscheiden. Der Trainingsschritt beinhaltet die Berechnung und Anwendung von Gradienten für sowohl den Generator als auch den Diskriminator, basierend auf ihren jeweiligen Verlustfunktionen.
Als Optimierungstechnik wird der Gradientenabstiegsverfahren angewendet, bei der die Parameter in Richtung des negativen Gradienten der Verlustfunktion aktualisiert werden, um den Verlust zu minimieren. Die Parameter beider Modelle werden jeweils mittels korrespondierenden Optimizers aktualisiert.
\\\newline
Die Wahl der Hyperparameter, einschließlich Anzahl der Epochen, Lernraten der Optimziers und die $LAMBDA$-Werte der jeweiligen Architekturen, wurde durch abgestimmte Experimente ermittelt. Dabei wurde darauf geachtet, dass die gewählten Werte zu einer stabilen und konvergenten Schulung führen.

\subsection{Optimizers}
Der Einsatz von Optimizers dienen zur Aktualisierung der Modelle basierend auf den Ergebnissen der Verlustfunktionen. Sie kontrollieren den Lernprozess von Neuronalen Netzwerken, in dem sie die Werte für die Parameter finden, so dass der Verlust am geringsten ist. Die Lernrate bestimmt dabei die Geschwindigkeit, wie schnell das Modell lernt und skaliert den Gradienten. 

In der Implementierung wird der Adam-Optimizer verwendet, welcher einer der gängisten Auswahl bei GAN Literaturen ist. Diese sind eine verbesserte Variante des stochastiscen Gradientenabstiegsverfahren, um die Lernraten für jede Variable dynamisch anzupassen. Dies trägt dazu bei, die Konvergenz des Trainingsprozesses zu beschleunigen und ihn robuster gegenüber unterschiedlichen Lernraten zu machen \cite{Kingma.2014}. 

\begin{lstlisting}[language=pyhaff, caption={Initialisierung der Adam-Optimizers aus Pix2Pix Implementierung}, label={cod:optimizer}]
generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
discriminator_optimizer= tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
\end{lstlisting}

\subsection{Fortschrittsüberwachung}
Um die inkrementellen Verbesserungen nach jeder Iteration zu visualisieren, wird während des Trainings ein Bild aus dem Trainingsdatensatz ausgewählt, auf das der Generator angewendet wird. Die Eingabebilder und die generierten Bilder werden mithilfe der Matplotlib- und Tensorflow-Bibliotheken gespeichert, um sie nach dem Training zugänglich und vergleichbar zu machen.

Zusätzlich werden der Verlust des Generators und des Diskriminators nach jeder Epoche in einer CSV-Datei festgehalten. Dies ermöglicht die Erstellung einer Verlustkurve mithilfe der Matplotlib-Bibliothek, um den Verlauf visuell zu überprüfen.

Diese systematischen Vorgehensweisen ermöglichen eine umfassende Überprüfung der Modellleistung und bieten visuelle Einblicke in den Fortschritt während des Trainingsprozesses.