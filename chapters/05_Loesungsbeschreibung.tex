\chapter{Lösungsbeschreibung}
\section{Training- und Testdaten}
Das Training und die Evaluierung von Generative Adversarial Networks (GANs) erfordern die klare Definition von Trainings- und Testdatensätzen. Der entscheidende Unterschied zwischen diesen Datensätzen besteht darin, dass das Modell während des Trainings auf den Trainingsdaten optimiert wird, während die Testdaten verwendet werden, um die Leistung und die Generalisierungsfähigkeiten des Modells zu bewerten.

\subsection{Datenladung für GAN-Training}
Für das effektive Training von GANs ist der Zugriff auf qualitativ hochwertige Datensätze von entscheidender Bedeutung. In diesem Kontext bietet TensorFlow eine umfassende Sammlung öffentlich verfügbarer Datensätze. Die verwendeten Datensätze werden von der Quelle \url{https://efrosgans.eecs.berkeley.edu} heruntergeladen und lokal extrahiert.

\lstinputlisting[language=pyhaff, caption=Laden eines Datensatzes von einer URL]{code/LadenDatensatz.txt}

Die Transformation und Vorverarbeitung der Bilddaten erfolgt durch die TensorFlow-Datensatz-API. Diese API bietet eine effiziente Datenpipeline für das Laden und Verarbeiten von Daten, insbesondere für den Einsatz in Machine-Learning-Modellen. In den folgenden Implementierungen werden die Datensätze durch eine Liste von Dateipfaden als Zeichenketten erzeugt.

\begin{lstlisting}[language=pyhaff, caption={Erzeugung eines Tensorflow-Dataset aus der CycleGAN Implementierung}, label={cod:createDataset}]
train_horses =  tf.data.Dataset.list_files(str(PATH / 'trainA/*.jpg')) 
\end{lstlisting}

\subsection{Vorverarbeitung des Datensatzes}

Um die Leistung von GAN-Modellen zu optimieren, werden vor dem Training Variationen in den Trainingsdaten eingeführt. Dieser Prozess umfasst Datenjittering und Normalisierung. Durch die Integration von Variationen wird das Modell robuster, da es eine erhöhte Invarianz gegenüber unterschiedlichen Eingabedaten entwickelt. Dies trägt wesentlich dazu bei, eine verbesserte Konvergenz während des Trainings zu erreichen.
\\\newline
Bei Pix2Pix bestehen die Trainingsdaten aus einem Paar von Eingabe- und Zielbildern, während bei CycleGAN unpaare Daten berücksichtigt werden. Um eine konsistente Skalierung mit der Tanh-Aktivierungsfunktion sicherzustellen, werden diese Bilder im Bereich von -1 bis +1 skaliert. Diese Normalisierung ist von entscheidender Bedeutung für die Stabilisierung des Trainingsprozesses. Durch die Bereitstellung eines standardisierten Datensatzes kann das Modell effektiver mit einer verbesserten Lernrate und Konvergenzgeschwindigkeit arbeiten \cite{Radford.2015}.

\begin{lstlisting}[language=pyhaff, caption={Vorverarbeitung des Datensatzes: Normalisierung}, label={cod:normalizing}]
def normalize(image):
    image = (image / 127.5) - 1
    return image
\end{lstlisting}

Datenjittering bezieht sich auf die Einführung von zufälligen Variationen oder Veränderungen in den Trainingsdaten, was in der Implementierung durch zufälliges Zuschneiden und eine zufällige Spiegelung erreicht wird. Die heruntergeladenen Bilder mit einer Auflösung von 256x256 werden zuerst auf eine größere Größe von 286x286 skaliert, wobei die Nearest-Neighbor-Methode verwendet wird. 

\begin{lstlisting}[language=pyhaff, caption={Vorverarbeitung des Datensatzes: Jittering}, label={cod:jittering}]
def random_jitter(image):
    image = tf.image.resize(image, [286, 286], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)
    image = tf.image.random_crop(image, size=(286, 286, 3))
    image = tf.image.random_flip_left_right(image)
    return image
\end{lstlisting}

Diese Methode skaliert Bilder einfach und effizient, indem sie für jedes Pixel im skalierten Bild den Farbwert des nächstgelegenen Pixels im Originalbild übernimmt\footnote{\url{https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation} \label{note:nearestNeighbor}}.
Nach dem Skalieren wird das Bild zufällig auf die Originalgröße reduziert und gleichzeitig mit einer Wahrscheinlichkeit von 50\% gespiegelt.
Anschließend werden die Bildpfade mittels der $load\_image$-Funktion geladen und in das resultierende JPEG-Format decodiert (Code \ref{cod:imageLoading}).
\\\newline
Die vorverarbeiteten Trainings- und Testbilder werden darauf in TensorFlow-Datasets integriert. Nachfolgend wird der Trainingsdatensatz zufällig gemischt und in Batches gruppiert, wodurch sichergestellt wird, dass das Modell nicht von der Reihenfolge der Datenpunkte beeinflusst wird.
\lstinputlisting[language=pyhaff, caption=Integration der vorverarbeiteten Trainingsbilder in Tensorflow-Datasets (CycleGAN Implementierung)]{code/LadenBild.txt}

Diese umfassende Vorverarbeitung stellt sicher, dass das GAN-Modell auf optimal vorbereiteten Daten trainiert wird, um eine maximale Leistung und Generalisierungsfähigkeit zu erreichen.

\input{chapters/pix2pix_implementierung.tex}
\input{chapters/cycleGan_implementation.tex}

\newpage
\section{Training und Hyperparameter}

Während des Trainings von GANs wird eine iterative Methode angewendet, bei der der Generator und der Diskriminator abwechselnd trainiert werden. Dieser Trainingszyklus erstreckt sich über mehrere Epochen, wobei in jeder Epoche Bilder durch einen Feed-Forward-Prozess vom Generator generiert und vom Diskriminator bewertet werden. Gleichzeitig wird der Diskriminator mit den echten Zielbildern trainiert, um seine Fähigkeit zu verbessern, zwischen echten und generierten Bildern zu unterscheiden. Der Trainingsschritt beinhaltet die Berechnung und Anwendung von Gradienten für sowohl den Generator als auch den Diskriminator, basierend auf ihren jeweiligen Verlustfunktionen (Code \ref{cod:pix2pixTrain}, \ref{cod:cycleTrain1}, \ref{cod:cycleTrain2}).
\\\newline
Die Wahl der Hyperparameter, einschließlich der Anzahl der Epochen, Lernraten der Optimizer und der $\lambda$-Werte der jeweiligen Architekturen, wurde durch abgestimmte Experimente ermittelt. Dabei wurde darauf geachtet, dass die gewählten Werte zu einer stabilen und konvergenten Schulung führen.
\\\newline
Um Überanpassung entgegenzuwirken, wird auf das Training mit umfangreichen Datensätzen zurückgegriffen. Die Integration zusätzlicher Regularisierung in Form von Dropout trägt dazu bei, die Generalisierungsfähigkeit des Modells zu steigern und seine Robustheit zu verbessern. Beim Dropout-Mechanismus werden während des Trainingsprozesses zufällig bestimmte Neuronen deaktiviert, was dazu führt, dass das Netzwerk nicht übermäßig abhängig von spezifischen neuronalen Pfaden wird. Diese Strategie fördert die Robustheit des Modells, indem sie es dazu zwingt, mit dem Fehlen bestimmter Neuronen umzugehen und alternative Pfade zu nutzen. Durch die erzwungene Redundanz werden verschiedene Teile des Netzwerks aktiviert, was zu einer breiteren Erfassung von Merkmalen und einer vielfältigeren Repräsentation führt. Dies ist entscheidend, um sicherzustellen, dass das Modell nicht zu stark auf spezifische Trainingsdaten reagiert, sondern stattdessen Merkmale erlernt, die auf einer breiteren Palette von Eingaben generalisiert werden können \cite{Yamashita.2018}. 

\subsection{Optimierungstechnik und Optimizers}
Als Optimierungstechnik wird das Gradientenabstiegsverfahren angewendet, bei dem die Parameter in Richtung des negativen Gradienten der Verlustfunktion aktualisiert werden, um den Verlust zu minimieren. Die Parameter beider Modelle werden mittels korrespondierenden Optimizern aktualisiert. Die Lernrate der Optimizer bestimmt die Geschwindigkeit, mit der das Modell lernt, und sie wird sorgfältig abgestimmt, um eine stabile und konvergente Schulung sicherzustellen.

In der Implementierung wird der Adam-Optimizer verwendet, eine gängige Wahl in der GAN-Literatur. Dieser Optimizer ist eine verbesserte Variante des stochastischen Gradientenabstiegsverfahrens und passt die Lernraten für jede Variable dynamisch an. Dadurch wird die Konvergenz des Trainingsprozesses beschleunigt und das Modell wird robuster gegenüber unterschiedlichen Lernraten \cite{Kingma.2014}.

\begin{lstlisting}[language=pyhaff, caption={Initialisierung der Adam-Optimizers aus der Pix2Pix Implementierung}, label={cod:optimizer}]
generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
discriminator_optimizer= tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
\end{lstlisting}

\subsection{Fortschrittsüberwachung und Visualisierung}
Um inkrementelle Verbesserungen nach jeder Iteration zu visualisieren, wird während des Trainings ein Bild aus dem Trainingsdatensatz ausgewählt, auf das der Generator angewendet wird. Die Eingabebilder und die generierten Bilder werden mithilfe der Matplotlib- und TensorFlow-Bibliotheken gespeichert, um sie nach dem Training zugänglich und vergleichbar zu machen. 

\begin{lstlisting}[language=pyhaff, caption={Speicherung der generierten Bilder}, label={cod:optimizer}]
def generate_images(model, test_input, tar, epoch):
  prediction = model(test_input, training=True)
  tf.keras.preprocessing.image.save_img(os.path.join(save_path, 'input_image.png'), test_input[0] * 0.5 + 0.5)
  tf.keras.preprocessing.image.save_img(os.path.join(save_path, 'ground_truth.png'), tar[0] * 0.5 + 0.5)
  tf.keras.preprocessing.image.save_img(os.path.join(save_path, 'predicted_image.png'), prediction[0] * 0.5 + 0.5)
\end{lstlisting}

Zusätzlich werden die Metriken zur Evaluation der Modelle, wie der Verluste des Generators und des Diskriminators, sowie die Genauigkeit des Diskriminators und der SSIM-Score nach jeder Epoche in einer CSV-Datei festgehalten (Code \ref{cod:csvSave}). Dieser Ansatz ermöglicht eine visuelle Überprüfung des Trainingsverlaufs und erleichtert die Identifikation von möglichen Verbesserungsbereichen.
Darüber hinaus ermöglicht die Datei die spätere Erstellung von Verlaufskurven für eine eingehendere Analyse (Code \ref{cod:curve}).
\newpage
Zur Initialisierung der Metriken kommen TensorFlow-Keras-Metriken zum Einsatz:
\begin{lstlisting}[language=pyhaff, caption={Initialisierung der Metriken}, label={cod:initMetrics}]
gen_loss_metric = tf.keras.metrics.Mean()
disc_loss_metric = tf.keras.metrics.Mean()
disc_accuracy_metric = tf.keras.metrics.BinaryAccuracy(threshold=0.5)
\end{lstlisting}

Diese Metriken werden verwendet, um den durchschnittlichen Verlust des Generators, den durchschnittlichen Verlust des Diskriminators und die Genauigkeit des Diskriminators zu erfassen.

Während des Trainingsprozesses wird für jeden Batch von Trainingsbildern der Verlust und die Genauigkeit berechnet. Die Verluste werden durch die oben genannten Metriken erfasst und nach jeder Epoche in die CSV-Datei aufgezeichnet. Die Genauigkeit des Diskriminators wird durch die BinaryAccuracy-Metrik überwacht, wobei ein Schwellenwert von 0,5 festgelegt ist, was in binären Klassifikationsaufgaben typisch ist.
\\\newline
Die Berechnung und Aktualisierung der Metriken erfolgen wie in dem Codeausschitt \ref{cod:updateMetrics} gezeigt.

\begin{lstlisting}[language=pyhaff, caption={Aktualisierung der Metriken}, label={cod:updateMetrics}]
gen_loss, disc_loss, disc_real_output, disc_generated_output = train_step(input_image, target, epoch, train_discriminator=True)
gen_loss_metric(gen_loss)
disc_loss_metric(disc_loss)

# Echte Bilder : Label 1, generierte Bilder :Label 0
real_labels = tf.ones_like(disc_real_output)
generated_labels = tf.zeros_like(disc_generated_output)
disc_accuracy_metric.update_state(real_labels, disc_real_output)
disc_accuracy_metric.update_state(generated_labels, disc_generated_output)
\end{lstlisting}

Der SSIM-Score kann mithilfe der TensorFlow-Funktion $tf.image.ssim()$ berechnet werden (Code \ref{cod:ssim}).
\\\newline
Diese systematischen Vorgehensweisen ermöglichen eine umfassende Überprüfung der Modellleistung und bieten visuelle Einblicke in den Fortschritt während des Trainingsprozesses.