\subsubsection{Architektur der Generatoren}
Die Architektur der Generatoren in CycleGAN spielt eine entscheidende Rolle bei der erfolgreichen Durchführung von Bildübersetzungen zwischen unterschiedlichen Domänen. Typischerweise basieren die Generatoren auf dem Residual-Netzwerk (ResNet)-Ansatz, der für seine Fähigkeit, tiefe neuronale Netzwerke zu trainieren, bekannt ist.
\\
ResNet-Blöcke, bestehend aus Convolutional-Schichten, Normalisierungsschichten und Aktivierungsfunktionen, ermöglichen den Generatoren, komplexe Transformationen durchzuführen. Die Nutzung von ResNet-Blöcken erleichtert auch das Training tiefer Netzwerke, was wichtig ist, um hochwertige Übersetzungen zu erreichen.

\subsubsection{Architektur der Diskriminatoren}
Ebenso wie beim Pix2Pix ist die gängige Architektur für die Diskriminatoren in CycleGAN der PatchGAN. 
%Die Architektur der Diskriminatoren in CycleGAN spielt eine entscheidende Rolle bei der Unterscheidung zwischen echten und generierten Bildern. Die Struktur beeinflusst direkt die Fähigkeit des Modells, realistische Übersetzungen zu erzeugen.
\\
%Eine gängige Architektur für die Diskriminatoren in CycleGAN ist der PatchGAN. Hierbei handelt es sich um eine Netzwerkstruktur, die das Bild in kleine Patches aufteilt und jeden Patch separat klassifiziert. Diese Methode ermöglicht eine feine Unterscheidung zwischen echten und generierten Bildern auf lokaler Ebene.
\\
Die Diskriminatoren bestehen in der Regel aus Convolutional-Schichten, gefolgt von Normalisierungsschichten und Aktivierungsfunktionen. In einigen Implementierungen von CycleGAN wird statt der üblichen Batch-Normalisierung die Instance Normalisierung bevorzugt.
\\
Die Instance Normalisierung ist eine Variante der Normalisierung, die auf Instanzebene durchgeführt wird. Im Gegensatz zur Batch-Normalisierung, bei der die Normalisierung über die gesamte Batch-Dimension erfolgt, betrachtet die Instance Normalisierung jede Instanz oder jedes Bild einzeln. Dies kann besonders vorteilhaft sein, wenn die statistischen Eigenschaften der einzelnen Instanzen variieren.

Die Verwendung von Instance Normalisierung in den Diskriminatoren von CycleGAN kann dazu beitragen, eine stabilere und konsistentere Konvergenz während des Trainings zu erreichen. 

\subsubsection{Training}
Das Training von CycleGAN erfolgt durch einen kompetitiven Prozess. Die Generatoren $G$ und $F$ konkurrieren mit den zugehörigen Diskriminatoren $D_X$ und $D_Y$. $D_X$ versucht, zwischen den von $F$ generierten und den echten Bildern aus $X$ zu unterscheiden, während $D_Y$ die von $G$ generierten Bilder von den echten aus der Domäne $Y$ unterscheidet. Die adversarialen Verluste werden dabei optimiert, um sicherzustellen, dass die generierten Bilder für die Diskriminatoren kaum von den echten zu unterscheiden sind.

\subsubsection{Cycle - Konsistenz}
Der CycleGAN führt zusätzlich einen Cycle-Konsistenz ein. Diese gewährleistet, dass die Übersetzungen zwischen den Domänen sowohl vorwärts ($X$ nach $Y$) als auch rückwärts ($Y$ nach $X$) konsistent sind. Die Cycle-Konsistenz fördert die Generierung qualitativ hochwertiger und konsistenter Übersetzungen.
\\
Die Kernidee besteht darin, dass nach der Übersetzung von $X$ nach $Y$ und zurück nach $X$ das resultierende Bild dem ursprünglichen $X$ entsprechen sollte. Dabei wird die Differenz zwischen dem ursprünglichen Bild $x$ mit dem zyklisch übersetzten Bild $F(G(x))$ mittels dem L1-Verlustfunktion minimiert. 
\\
Diese zyklische Konsistenz stellt sicher, dass die Generatoren konsistente und realitätsnahe Übersetzungen zwischen den Domänen erzeugen.

\subsubsection{Identity - Loss}
Zusätzlich zu adversarialen und zyklischen Verlusten spielt der Identitätsverlust eine bedeutende Rolle im Training von CycleGAN. Der Identitätsverlust zielt darauf ab, sicherzustellen, dass die Transformationen nicht zu stark sind und wichtige Merkmale der Ausgangsbilder bewahrt bleiben. Dieser Verlust wird durch die Verwendung von Bildern der jeweiligen Ausgangsdomäne als Eingabe für den Generator und die Berechnung des Verlusts zwischen den generierten und den Eingangsbildern erreicht.

Die Identitätsverluste für $G$ und $F$ werden als zusätzliche Terme in die Gesamtverlustfunktion integriert. Dieser Mechanismus stellt sicher, dass der Generator nicht unerwünschte Veränderungen vornimmt und hilft, feine Details und Strukturen in den generierten Bildern zu erhalten.