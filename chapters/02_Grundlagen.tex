\chapter{Grundlagen}

\section{Generative Adversarial Netowrks}
Generative Adversarial Networks, kurz GANs, sind eine aufstrebende Technologie im Bereich des maschinellen Lernens und der künstlichen Intelligenz. Inspiriert von Ian Goodfellow und seinen Kollegen im Jahr 2014, bieten GANs eine effiziente Möglichkeit, tiefe Repräsentationen von Daten zu erlernen, ohne dass große Mengen an annotierten Trainingsdaten benötigt werden\cite{Creswell.2018}. 
Dies wird durch die Verwendung von Backpropagation und den Wettbewerb zwischen zwei neuronalen Netzen - dem Generator und dem Diskriminator - erreicht. 
Daraus ergeben sich zahlreiche neue Ansätze zur Generierung realistischer Inhalte. 
Die Anwendungen reichen von der Bildgenerierung bis hin zur Superauflösung und Textgenerierung \cite{Aggarwal.2021}.

\subsection*{Funktionsweise}
Der Generator und der Diskriminator sind die Hauptkomponenten eines GAN. Die beiden neuronalen Netze werden gleichzeitig trainiert und konkurrieren miteinander, wobei der Generator versucht, den Diskriminator zu täuschen, indem er synthetische Inhalte erzeugt. Um die Glaubwürdigkeit des Generators zu erhöhen, so dass der Diskriminator nicht mehr zwischen den Eingaben unterscheiden kann, wird das gesamte Netz trainiert. Die Netze werden in der Regel als mehrschichtige Netzwerke implementiert, die aus Convolutional und Fully-Connected Schichten bestehen\cite{Creswell.2018}.

\subsubsection*{Generator}
Der Generator dient zur Erzeugung künstlicher Daten wie Bilder und Texte. 
Der Generator ist nicht mit dem realen Datensatz verbunden und lernt daher nur durch die Interaktion mit dem Diskriminator. Wenn der Diskriminator nur noch 50\% der Eingaben richtig vorhersagt, gilt der Generator als optimal\cite{Creswell.2018}.

\subsubsection*{Diskriminator}
Die Unterscheidung zwischen echten und unechten Eingaben ist Aufgabe des Diskriminators. Der Diskriminator kann sowohl künstliche als auch reale Daten verwenden. 
Wenn der Diskriminator nicht mehr richtig unterscheiden kann, wird er als konvergierend bezeichnet\cite{Aggarwal.2021}. Andernfalls wird er als optimal bezeichnet, wenn seine Klassifizierungsgenauigkeit maximiert ist. Im Falle eines optimalen Diskriminators wird das Training des Diskriminators gestoppt und der Generator trainiert alleine weiter, um die Genauigkeit des Diskriminators wieder zu verbessern\cite{Creswell.2018}.

\subsubsection*{Training}
Das Training besteht in der Optimierung der Parameter für sowohl den Generator als auch den Diskriminator durch die Anwendung von Backpropagation zur Verbesserung dieser Parameter. Dieses Verfahren wird häufig als anspruchsvoll und instabil beschrieben. Einerseits gestaltet sich die Herausforderung, beide Modelle konvergieren zu lassen. Andererseits besteht die Problematik darin, dass der Generator Muster erzeugen kann, die für verschiedene Eingaben äußerst ähnlich sind, was als "Mode-Collapse-Problem" bekannt ist. Der Diskriminatorverlust kann sich rasch gegen Null konvergieren, wodurch ein zuverlässiger Gradientenfluss für die Aktualisierung des Generators verhindert wird.
Zur Bewältigung dieser Herausforderungen wurden verschiedene Lösungsansätze vorgeschlagen. Ein Beispiel ist die Verwendung heuristischer Verlustfunktionen. Eine alternative Strategie, die von Sonderby et al. vorgeschlagen wurde, besteht darin, den Datensatz vor der Verwendung zu verrauschen (vgl. Creswell et al., 2018).

\subsubsection*{Adversarieller Verlust}
Der adversarielle Verlust, auch als GAN-Verlust bekannt, spielt eine zentrale Rolle im Trainingsprozess. Dieser Verlust basiert auf dem Konzept des Minimax-Spiels zwischen dem Generator und dem Diskriminator. Der Generator strebt danach, den Diskriminator zu überlisten und Daten zu erzeugen, die von echten Daten nicht zu unterscheiden sind. Gleichzeitig ist es das Ziel des Diskriminators, zwischen echten und generierten Daten zu differenzieren. Der adversarielle Verlust wird in der Gleichung 2.1 repräsentiert.

\begin{equation}
    \min_G \max_D V(D, G) = \mathbb{E}_{x\sim p_{\text{data}}(x)}[\log D(x)] + \mathbb{E}_{z\sim p_z(z)}[\log(1 - D(G(z)))]
\end{equation}

Hierbei bezeichnet $G$ den Generator, $D$ den Diskriminator, $x$ echte Daten, $z$ das Rauschen und $p_{data}$ sowie $p_z$ die Wahrscheinlichkeitsverteilungen von echten Daten und Rauschen. Der Minimax-Ansatz impliziert, dass der Generator versucht, den Verlust zu minimieren, während der Diskriminator versucht, ihn zu maximieren. Eine gezielte Optimierung und Anpassung des adversariellen Verlusts ist entscheidend, um Herausforderungen wie dem Mode-Collapse-Problem und den Konvergenzproblemen zu begegnen \cite{Hong.2020}.

\subsection*{Anwendungen}
GAN wurde ursprünglich für unüberwachtes maschinelles Lernen entwickelt. Die Architektur liefert jedoch ebenso gute Ergebnisse beim halbüberwachten Lernen und beim Reinforcement Learning\cite{Aggarwal.2021}. 
Aus diesem Grund wird sie in einer Vielzahl von Bereichen wie dem Gesundheitswesen, dem Maschinenbau und dem Bankwesen eingesetzt. Beispielsweise wird GAN in der Medizin zur Erkennung und Behandlung chronischer Krankheiten eingesetzt. Aber auch die Identifikation von 3D-Objekten und die Generierung von realen Bildern und Texten ist durch den Einsatz von GANs möglich.

\section*{Limitationen}
Ein kritisches Problem von GANs ist die Instabilität des Trainings aufgrund von Mode-Collapse, was die Weiterentwicklung des generativen Lernens und potentielle Anwendungen einschränkt\cite{Liu.2022}. Der Generator lernt nur Bilder bestimmter Arten der Datenverteilung.  Andere Arten, die ebenfalls in der Verteilung vorkommen, werden hingegen vernachlässigt\cite{Srivastava.2017}. Ansätze wie das Hinzufügen von Rauschen zum Netzwerk, eine Manifold Entropy Estimation \cite{Liu.2022} und implizites Variationslernen \cite{Srivastava.2017} wurden bereits vorgeschlagen, um dieses Problem zu lösen.\\
Des Weiteren birgt die Fähigkeit eines GANs zur Generierung von Inhalten, die nahezu identisch mit authentischen Inhalten sind, potenzielle Herausforderungen in realen Szenarien, insbesondere im Zusammenhang mit der menschlichen Bildsynthese. Diese Fähigkeit ermöglicht es Betrügern, gefälschte Profile in sozialen Medien zu erstellen. Gezielte Anwendungen von GANs, die darauf ausgelegt sind, einzigartige und realistische Bilder von Personen zu erzeugen, die in der Realität nicht existieren, könnten die Erstellung falscher Profile erschweren\cite{Aggarwal.2021}.


\section{Pix2Pix}
Isola et al., hat sich als zentrales Framework für Bild-zu-Bild-Übersetzungen auf der Basis von bedingten generativen adversariellen Netzwerken (cGANs) etabliert. Es ermöglicht die Erstellung einer abstrakten Abbildung von einem Eingangsbild zu einem korrespondierenden Ausgangsbild und bewältigt dabei eine vielfältige Palette an Bildübersetzungsaufgaben, wie die Transformation von Skizzen in realistische Bilder oder die Konvertierung von Tages- zu Nachtaufnahmen. \newline
Pix2Pix fungiert hier als Generative Adversarial Network (GAN), spezialisiert auf diverse Formen der Bildübersetzung. Darunter fallen die Umwandlung von Schwarz-Weiß-Fotos in Farbbilder, die Transformation von Skizzen in realistische Bilder, und relevant für diese Arbeit, die Konvertierung von Satellitenbildern in kartographische Darstellungen, ähnlich den Visualisierungen von Google Maps.
  

\input{chapters/pix2pix_kernkonzepte.tex}

\subsection{Anwendungen von Pix2Pix}
 Dieser umfassende Ansatz ermöglicht es Pix2Pix, sich flexibel an eine Vielzahl von Problemen anzupassen, die in der Vergangenheit unterschiedliche und spezialisierte Ansätze für die Verlustfunktion erforderten. Dadurch wird die breite Anwendbarkeit und Effektivität des Pix2Pix-Modells in verschiedenen Bildübersetzungsaufgaben deutlich.

\section{CycleGAN}
CycleGAN, das 2017 von Jun-Yan Zhu et al. vorgestellt wurde, stellt eine neue Entwicklung im Bereich des maschinellen Lernens und insbesondere der Bildübersetzung zwischen unpaaren Domänen dar. Es erweitert die Pix2Pix-Architektur durch die Einführung einer Zykluskonsistenz-Verlustfunktion (Cycle Consistency Loss), die sicherstellt, dass das Originalbild nach einem Übersetzungs- und Rückübersetzungszyklus erhalten bleibt. Der Generator $G$ transformiert Bilder aus der Domäne $X$ in die Domäne $Y$, während der Generator $F$ den umgekehrten Prozess durchführt. Diese Transformationen werden ohne gepaarte Trainingsdaten durchgeführt.

\subsection{CycleGAN - Kernkonzepte}
\input{chapters/cycleGan_chapter.tex}

\section{Layers}
\subsection{Convolutional Layer}
Convolutional Layers sind eine entscheidende Komponente in neuronalen Netzwerken, insbesondere bei der Verarbeitung von Bildinformationen. Diese Schicht verwendet Convolution-Operationen, um lokale Muster in den Eingabedaten zu erkennen. Die Filter (auch als Kernels bezeichnet), die über das Eingangsbild verschoben werden, erfassen bestimmte Merkmale wie Kanten oder Texturen. Diese Merkmale werden hierarchisch extrahiert, wobei tiefere Schichten komplexere und abstraktere Informationen repräsentieren. Durch die Verwendung von Convolutional Layers wird die Anzahl der zu trainierenden Parameter reduziert, was die Effizienz des Modells verbessert und die räumliche Hierarchie der Merkmale bewahrt. Mathematisch ausgedrückt erfolgt die Convolution-Operation durch Faltung der Eingabedaten mit den Filterkernen.

\subsection{Fully-Connected Layer}
Fully-Connected Layers, auch als Dense Layers bekannt, sind Schlüsselkomponenten in neuronalen Netzwerken, die für die Integration globaler Kontextinformationen und die Klassifikation verantwortlich sind. Jede Einheit in dieser Schicht ist mit jeder Einheit der vorherigen und nachfolgenden Schicht verbunden, was eine vollständige Vernetzung ermöglicht. Die Gewichtungen dieser Verbindungen werden während des Trainings angepasst, um komplexe nichtlineare Beziehungen zwischen den Merkmalen zu modellieren. Fully-Connected Layers werden häufig am Ende eines neuronalen Netzwerks verwendet, um die extrahierten Merkmale in eine Ausgabe umzuwandeln. Mathematisch ausgedrückt wird die Aktivierung dieser Schicht durch eine Matrixmultiplikation der Eingabe mit den Gewichtungsmatrizen und das Hinzufügen von Bias-Werten berechnet. Diese Schichten ermöglichen die Erzeugung von hochdimensionalen Darstellungen, die für die Aufgaben wie Klassifikation und Regression von zentraler Bedeutung sind.

\section{Bibliotheken}
\subsection{Tensorflow}
TensorFlow ist ein weit verbreitetes Open-Source-Framework, das für maschinelles Lernen und tiefe neuronale Netzwerke eingesetzt wird\footnote{https://www.tensorflow.org/}. Es bietet eine umfangreiche Plattform zur Entwicklung und Umsetzung von Modellen in verschiedenen Anwendungsbereichen, darunter Bilderkennung und natürliche Sprachverarbeitung. Die Architektur von TensorFlow ermöglicht das Erstellen komplexer maschineller Lernanwendungen und stellt umfassende Tools und Bibliotheken zur Verfügung, um den gesamten Entwicklungsprozess zu unterstützen. Darüber hinaus profitiert TensorFlow von einer aktiven und engagierten Community, die kontinuierlich zur Weiterentwicklung des Frameworks beiträgt\footnote{https://github.com/tensorflow/tensorflow}.

\subsection{Keras}
Ursprünglich als eigenständiges Framework konzipiert und seit TensorFlow 2.0 in die TensorFlow Core API integriert, fungiert Keras als Open-Source-API zur Modellierung von Strukturen im Bereich des Deep Learning\footnote{https://www.tensorflow.org/guide/keras}. Diese Bibliothek, die in der Programmiersprache Python implementiert ist, umfasst sämtliche Phasen des maschinellen Lern-Workflows. Beginnend mit der Datenverarbeitung ermöglicht sie eine Fortführung bis zur präzisen Abstimmung der Hyperparameter während des Trainingsprozesses. Die Keras-Prinzipien zeichnen sich durch Einfachheit, Flexibilität und Leistungsfähigkeit aus und ermöglichen es den Anwendern, die Skalierbarkeit und plattformübergreifenden Fähigkeiten der TensorFlow-Plattform zu nutzen.\footnote{https://keras.io/about/}.