Seien die Datensätze $X: Maps$ und $Y: Sateliten$, $G: X\rightarrow Y$ und $F: Y\rightarrow X$ die Generatoren sowie $D_X$ und $D_Y$ die Diskriminatoren, die jeweils zwischen Bilder in der Domäne $X$ und $Y$ unterscheiden. 
\\\newline
In allen Durchläufen zeigt sich, dass die Generatoren Probleme mit feinen und detailreichen Details haben. Weil die meisten Trainingsbilder Straßen und Häuser zeigen, können die Generatoren besser die Straßenlinien erzeugen.

Bilder mit einer größeren Vielfalt wie Flüsse und Wälder sind eine größere Herausforderung für die Generatoren. Die Erstellung der Karten gestaltet sich schwierig in Bezug auf die Struktur und Farbkodierung. Oft werden diese Flächen in derselben Farbe wie die Straßen erzeugt, und es wird versucht, auf der Grundlage dieser großen Freiflächen kleine Straßen zu erzeugen. Bei allen Versuchen gab es Probleme bei der Erfassung feiner Strukturen in den Wäldern sowie bei der einheitlichen Farbkodierung der Flüsse in den Satellitenbildern. 
\\\newline
Für den Parameterwert $\lambda=0.0002$ wurden die besten Ergebnisse in Bezug auf den SSIM-Score und die Testgenauigkeiten der Diskriminatoren erzielt. Der SSIM-Score für den Generator $F$ (Generierung der Kartenansichten) beträgt $0.592$ mit einem Unterschied von $0.012$ zum zweitbesten Ergebnis. Für den Generator $G$ beträgt der SSIM-Score $0.198$. Obwohl die visuelle Ähnlichkeit zwischen den generierten Satellitenbildern auf den ersten Blick hoch erscheint, zeigt eine genauere Betrachtung, dass kleinere Strukturen im generierten Bild fehlen. Dies spiegelt sich im vergleichsweise niedrigen SSIM-Score wieder. Die Genauigkeiten der Diskriminatoren liegen bei $50.1\%$ für $D_Y$ und $48.5\%$ für $D_X$, was nahezu optimal ist.
\\\newline
Das Training zeigt sich als instabil und es besteht die Möglichkeit eines Modekollapses. Die Verlustkurve der Generatoren folgt einem exponentiellen Zerfall, bei dem ein bestimmter Wert ab einer bestimmten Epoche approximiert wird. Im Gegensatz dazu weist der SSIM-Score einen langsamen Anstieg auf, was darauf hindeutet, dass die Generatoren zwar ihre Verluste minimieren, aber möglicherweise nicht mit der gewünschten visuellen Qualität einhergehen.

Die generierten Bilder weisen nach diesem Zeitpunkt bereits visuell die grobe Struktur des zu generierten Bilds auf und variieren sich nicht mehr stark. Jedoch, wie auch der SSIM-Score zeigt, können die Generatoren für weitere feinere Details und Farbübereinstimmungen keine signifikante Verbesserung aufweisen.

Betrachtet man den SSIM-Score für die Zyklusübersetzung, so steigt dieser exponentiell an. Dies deutet darauf hin, dass der Zykluskonsistenz-Verlust einen bedeutenden Einfluss auf das Training ausübt. Die exponentielle Zunahme des SSIM-Scores könnte darauf hinweisen, dass die Konsistenz zwischen den Original- und zurückübersetzten Bildern mit der Zeit stetig zunimmt, was auf eine Verbesserung der Generatoren hinsichtlich ihrer Fähigkeit zur Zyklusübersetzung hindeutet. Rundum betragen die SSIM-Scores für die Zyklusübersetzung $80\%$ für $Y$ und $90\%$ für $X$.

Für die Trainingsdaten bleibt die Genauigkeit der Diskriminatoren stabil um die $50\%$. Jedoch ergeben sich hohe Schwankungen je nach Epoche für die Testdaten, insbesondere für $D_Y$. Dies weist darauf hin, dass die Diskriminatoren möglicherweise Schwierigkeiten haben, mit neuen, nicht trainierten Daten umzugehen, was auf Überanpassung oder mangelnde Generalisierungsfähigkeit des Modells trotz der existierenden Maßnahmen, wie das Hinzufügen von Rauschen und Dropout-Schichten hinweisen könnte. 

\begin{figure}
    \begin{subfigure}[t]{.4\textwidth}
      \centering
      \includegraphics[width=\linewidth]{example-image-a}
      \caption{\textbf{Schnitt}: $A \cup B$: Element liegt in $A$ \textbf{oder} in $B$.}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.4\textwidth}
      \centering
      \includegraphics[width=\linewidth]{example-image-b}
      \caption{\textbf{Vereinigung}: $A \cap B$: Element liegt in $A$ \textbf{und} in $B$.}
    \end{subfigure}
  
    \medskip
  
    \begin{subfigure}[t]{.4\textwidth}
      \centering
      \includegraphics[width=\linewidth]{example-image-c}
      \caption{\textbf{Differenz}: $A \setminus B$: Element liegt in $A$ \textbf{nicht} in $B$. (\textit{A ohne B})}
    \end{subfigure}
    \hfill
    \begin{subfigure}[t]{.4\textwidth}
      \centering
      \includegraphics[width=\linewidth]{example-image-a}
      \caption{\textbf{Symmetrische Differenz}: $A \Delta B$: Element liegt \textbf{entweder} in $A$ oder in $B$.}
    \end{subfigure}
  \end{figure}

  Die Laufzeit des Trainings spiegelt die Komplexität der Modelle wider, insbesondere auf der GPU, wo jede Epoche im Durchschnitt etwa 2 Minuten dauert. Im Vergleich dazu benötigt die CPU, selbst nach einer Reduzierung der Residualblöcke auf einen Block, rund 6 Minuten pro Epoche. Die Nutzung von Instanznormalisierung trägt zur beschleunigten Konvergenz und Verbesserung der Laufzeit bei. Zudem zeigt sich, dass die Verwendung von Residualblöcken eine bessere Laufzeit ermöglicht im Vergleich zu Generatoren mit zusätzlichen Schichten. 